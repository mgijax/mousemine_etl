[DEFAULT]
BIN=%(BASEDIR)s/bin
PDIR=%(ODIRBASE)s/%(__name__)s
ODIR=%(PDIR)s/%(TIMESTAMP)s
CAT=cat
CP=cp
CURL=curl %(CURLTIMEOUT)s --silent --verbose 2>> %(LOGFILE)s
CURLTIMEOUT=-m 900
ECHO=echo
GREP=grep
LOGFILE=%(ODIRBASE)s/LOG
MKDIR=mkdir
MV=mv
PYTHON=python3
RM=rm
SED=sed
TAR=tar
UNZIP=unzip
ZCAT=zcat

#
# With ConfigParser and Python 2.6 (anything less than 3.2) there is NO WAY for a
# config value to contain a literal percent character.
# HACK: The refresh script will replace the following PCT string with a "%" character.
# This allows us to include encoded characters in URLs in this config file.
# For example, to to include a space (%20) character:
#   space: %(PCT)s20
#   myurl: http://someplace.com/path%(SPACE)swith%(SPACE)sspaces/
#
PCT=__LITERAL_PCT_CHAR__
SPACE=%(PCT)s20

# required: True
#       if the source fails, refresh.py with exit with a 1 
#       this will cause the jenkins build to fail 
#       and prevent mousemine from being built.
# required: False  (actually any string other than "True")
#       if the source fails, cached values for the source will be used.
required=False

# __PRE__ and __POST__ are concatenated before and after (resp.) every command (cmd variable)
#
# __PRE__: make sure errors are caught
__PRE__: 
    set -e -o pipefail

__POST__:

[strain-genomes]
__name__: strain-genomes
cmd:
    %(BIN)s/straindata/refresh %(ODIR)s %(LOGFILE)s 2>> %(LOGFILE)s

[emapa]
__name__: emapa
cmd:
    %(PYTHON)s %(BIN)s/libdump/dumpEMAPAobo.py > %(ODIR)s/EMAPA.obo 2>> %(LOGFILE)s

[cl]
__name__: cl
cmd:
    %(CURL)s https://raw.githubusercontent.com/obophenotype/cell-ontology/master/cl-basic.obo | grep -v "^holds_over_chain:" | grep -v "^transitive_over:" > %(ODIR)s/CellOntology.obo

[do]
__name__: do
cmd:
    %(CURL)s -o %(ODIR)s/doid-merged.obo https://raw.githubusercontent.com/DiseaseOntology/HumanDiseaseOntology/main/src/ontology/doid-merged.obo
    %(PYTHON)s %(BIN)s/libdump/filterDiseaseOntology.py < %(ODIR)s/doid-merged.obo > %(ODIR)s/DiseaseOntology.obo
    %(RM)s %(ODIR)s/doid-merged.obo

[go]
__name__: go
cmd:
    # filter out consider: lines to avoid issue of referenceing an obsolete term
    %(CURL)s -L http://purl.obolibrary.org/obo/go.obo | grep -v "^consider:" > %(ODIR)s/GeneOntology.obo

[mp]
__name__: mp
cmd:
    %(CURL)s "http://www.informatics.jax.org/downloads/reports/MPheno_OBO.ontology" | grep -v  '\(^created_by\)\|\(^creation_date\)' > %(ODIR)s/MammalianPhenotype.obo 

[uberon]
__name__: uberon
cmd:
    %(CURL)s -o %(ODIR)s/uberon.obo http://svn.code.sf.net/p/obo/svn/uberon/trunk/uberon.obo

[ma]
__name__: ma
cmd:
    %(CURL)s -o %(ODIR)s/MA.obo http://www.berkeleybop.org/ontologies/ma.obo

[psi-mi]
__name__: psi-mi
cmd:
    %(CURL)s -o %(ODIR)s/psi-mi.obo https://raw.githubusercontent.com/HUPO-PSI/psi-mi-CV/master/psi-mi.obo

[mgi-base]
__name__: mgi-base
required:
    True 
cmd: 
    %(PYTHON)s %(BIN)s/dumpMgiItemXml.py -d %(ODIR)s --logfile %(LOGFILE)s
    %(MKDIR)s -p %(PDIR)s/empty
    %(ECHO)s '<?xml version="1.0"?> <items> </items>' > %(PDIR)s/empty/Items.xml

[yeastmine]
__name__: yeastmine
cmd:
    %(PYTHON)s %(BIN)s/libdump/fmfd.py -d %(ODIR)s -o yeast -l %(LOGFILE)s

[zebrafishmine]
__name__: zebrafishmine
cmd:
    %(PYTHON)s %(BIN)s/libdump/fmfd.py -d %(ODIR)s -o zebrafish -l %(LOGFILE)s

[ratmine]
__name__: ratmine
cmd:
    %(PYTHON)s %(BIN)s/libdump/fmfd.py -d %(ODIR)s -o rat -l %(LOGFILE)s

[flymine]
__name__: flymine
cmd:
    %(PYTHON)s %(BIN)s/libdump/fmfd.py -d %(ODIR)s -o fly -l %(LOGFILE)s

[wormmine]
__name__: wormmine
cmd:
    %(PYTHON)s %(BIN)s/libdump/fmfd.py -d %(ODIR)s -o worm -l %(LOGFILE)s

[entrez]
__name__: entrez
cmd:
    %(CURL)s ftp://ftp.ncbi.nih.gov/gene/DATA/gene_info.gz | %(ZCAT)s > %(ODIR)s/entrez

[homologene]
__name__: homologene
cmd:
    %(CURL)s ftp://ftp.ncbi.nih.gov/pub/HomoloGene/current/homologene.data > %(ODIR)s/homologene.data
    %(PYTHON)s %(BIN)s/libdump/filterNonGenes.py -u -t homologene %(ODIR)s/homologene.data

[panther]
__name__: panther
cmd:
    %(CURL)s -o %(ODIR)s/RefGenomeOrthologs.tar.gz ftp://ftp.pantherdb.org/ortholog/current_release/RefGenomeOrthologs.tar.gz 
    %(TAR)s -xzvf %(ODIR)s/RefGenomeOrthologs.tar.gz -C %(ODIR)s
    %(RM)s %(ODIR)s/RefGenomeOrthologs.tar.gz
    %(PYTHON)s %(BIN)s/libdump/filterNonGenes.py -u -t panther %(ODIR)s/RefGenomeOrthologs

[biogrid]
__name__: biogrid
cmd:
    %(CURL)s -o %(ODIR)s/BIOGRID-ORGANISM.psi25.zip https://downloads.thebiogrid.org/Download/BioGRID/Latest-Release/BIOGRID-ORGANISM-LATEST.psi25.zip
    %(UNZIP)s %(ODIR)s/BIOGRID-ORGANISM.psi25.zip 'BIOGRID-ORGANISM-Mus_musculus*' -d %(ODIR)s
    %(PYTHON)s %(BIN)s/libdump/filterNonGenes.py -u -t biogrid %(ODIR)s/*.xml

[intact]
__name__: intact
cmd:
    %(CURL)s -o %(ODIR)s/mouse.zip ftp://ftp.ebi.ac.uk/pub/databases/intact/current/psi25/species/mouse.zip
    %(UNZIP)s %(ODIR)s/mouse.zip -d %(ODIR)s
    %(RM)s %(ODIR)s/mouse.zip
    %(PYTHON)s %(BIN)s/libdump/filterNonGenes.py -u -t intact %(ODIR)s/*.xml

[uniprot]
__name__: uniprot
# Uniprot data for mouse (taxonid = 10090) includes proteins for mouse subspecies (e.g. Mus 
# musculus domesticus, M.m. bactrianus, etc.). The following defines a sed filter to convert
# taxon ids to 10090. E.g. look for lines like:
#    <dbReference type="NCBI Taxonomy" id="35531"/>
# and convert them to:
#    <dbReference type="NCBI Taxonomy" id="10090"/>
sedids=\(10091\|10092\|35531\|39442\|57486\|116058\|179238\|477815\|1643390\|1879032\|1385377\|46456\)
sedsearch=<dbReference type="NCBI Taxonomy" id="%(sedids)s"\/>
sedreplace=<dbReference type="NCBI Taxonomy" id="10090"\/>
sedcmd=%(SED)s 's/%(sedsearch)s/%(sedreplace)s/'
cmd:
    %(CURL)s "https://www.uniprot.org/uniprot/?format=xml&query=taxonomy:10090+AND+reviewed:yes&compress=yes" | %(ZCAT)s | %(sedcmd)s > %(ODIR)s/10090_uniprot_sprot.xml
    %(CURL)s "https://www.uniprot.org/uniprot/?format=xml&query=taxonomy:10090+AND+reviewed:no&compress=yes"  | %(ZCAT)s | %(sedcmd)s > %(ODIR)s/10090_uniprot_trembl.xml

[uniprot-keywords]
__name__: uniprot-keywords
cmd:
    %(CURL)s "ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/docs/keywlist.xml.gz" | %(ZCAT)s > %(ODIR)s/keywlist.xml

[uniprot-isoforms]
__name__: uniprot-isoforms
cmd:
    %(CURL)s "ftp://ftp.uniprot.org/pub/databases/uniprot/knowledgebase/uniprot_sprot_varsplic.fasta.gz" | %(ZCAT)s > %(ODIR)s/uniprot_sprot_varsplic.fasta

[interpro]
__name__: interpro
cmd:
    %(CURL)s ftp://ftp.ebi.ac.uk/pub/databases/interpro/interpro.xml.gz  | %(ZCAT)s > %(ODIR)s/interpro.xml

[protein2ipr]
__name__: protein2ipr
# The download file (protein2ipr.dat.gz) is over 3.5 GB compressed! So....
# (1) We use curl's -z option to only download if there's an update. Also, the file
# is placed in the parent directory (otherwise it would get deleted every time).
# (2) We leave it compressed, and zcat it through our filter (filterProtein2Ipr.py)
# to extract the tiny fraction we need. That fraction consists of the lines for 
# the proteins we actually load from uniprot.
# 
cmd:
    %(CAT)s %(ODIRBASE)s/uniprot/latest/*.xml | %(GREP)s '<accession>' | %(SED)s 's/<accession>\(.*\)<\/accession>/\1/' > %(PDIR)s/ids.txt
    %(CURL)s --silent --verbose -m 5400 "ftp://ftp.ebi.ac.uk/pub/databases/interpro/protein2ipr.dat.gz" -R -o %(PDIR)s/protein2ipr.dat.gz -z %(PDIR)s/protein2ipr.dat.gz
    %(ZCAT)s < %(PDIR)s/protein2ipr.dat.gz | %(PYTHON)s %(BIN)s/libdump/filterProtein2Ipr.py %(PDIR)s/ids.txt > %(ODIR)s/protein2ipr.dat

[reactome]
__name__: reactome
cmd:
    %(CURL)s https://reactome.org/download/current/UniProt2Reactome_All_Levels.txt -o %(ODIR)s/UniProt2Reactome_All_Levels.txt
